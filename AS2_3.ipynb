{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "##### To be Updated #####\n",
    "student_id = \"23xx04247\"\n",
    "#########################\n",
    "\n",
    "student_id = ''.join([i for i in student_id if i.isdigit()])\n",
    "random.seed(student_id)\n",
    "\n",
    "# set the number of iterations and learning rate\n",
    "iters = random.randint(100,300)\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Evaluate the function at x\n",
    "def C(x):\n",
    "    ##### To be Updated #####\n",
    "    return (x.T @ np.array([[2,1],[1,20]]) @ x) - (np.array([5,3]).reshape(2,1).T @ x)\n",
    "\n",
    "# Evaluate the gradient of function at x\n",
    "def dC(x):\n",
    "    ##### To be Updated #####\n",
    "    # 1. Compute and return the gradient\n",
    "    return (np.array([[4, 1], [1, 40]]) @ x) - np.array([5, 3]).reshape(2, 1)\n",
    "    #########################\n",
    "\n",
    "def plot_grad_change(X,Y,Z, c, grad_xs0, grad_xs1, grad_ys):\n",
    "    fig = plt.figure()\n",
    "    title_str = \"Gradient Descent:\"+\"lr=\"+str(learning_rate)\n",
    "    plt.title(title_str)\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    ax.plot_surface(X, Y, Z, cmap=plt.cm.YlGnBu_r,alpha=0.7)\n",
    "    for i in range(len(grad_xs0)):\n",
    "        ax.plot([grad_xs0[i]],[grad_xs1[i]], grad_ys[i][0], markerfacecolor='r', markeredgecolor='r', marker='o', markersize=7)\n",
    "    ax.text(grad_xs0[-1],grad_xs1[-1],grad_ys[-1][0][0],\n",
    "                 \"(\"+str(round(grad_xs0[-1],2))+\",\"+\n",
    "                     str(round(grad_xs1[-1],2))+\"),\"+\n",
    "                     str(round(grad_ys[-1][0][0],2)))\n",
    "    plt.show()\n",
    "    \n",
    "def GD(start,x,y,z, c, dc, iters, eta):\n",
    "    px = start.astype(float)\n",
    "    py = c(px).astype(float)\n",
    "    print(\"GD Start Point:\",px,py)\n",
    "    print(\"Num steps:\",iters)\n",
    "    grad_xs0, grad_xs1, grad_ys = [px[0][0]], [px[1][0]], [py]\n",
    "    \n",
    "    for iter in range(iters):\n",
    "        ##### To be Updated #####\n",
    "        # 2. Update px using gradient descent\n",
    "        px = px - eta * dc(px)\n",
    "        # 3. Update py\n",
    "        py = c(px)\n",
    "        #########################\n",
    "        grad_xs0.append(px[0][0])\n",
    "        grad_xs1.append(px[1][0])\n",
    "        grad_ys.append(py)\n",
    "    print(\"Converged Point:\",px,py)\n",
    "    plot_grad_change(x,y,z, c, grad_xs0,grad_xs1, grad_ys)\n",
    "\n",
    "\n",
    "lo = -10\n",
    "hi = 10\n",
    "x1 = round(random.uniform(lo,0),4)\n",
    "x2 = round(random.uniform(lo,0),4)\n",
    "x = np.linspace(lo, 1, hi)\n",
    "y = np.linspace(lo, 1, hi)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros_like(X)\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        Z[i][j] = C(np.array([[X[i][j]], [Y[i][j]]])).item()\n",
    "# start Gradient Descent\n",
    "GD(np.array([x1,x2]).reshape(2,1),X,Y,Z, C, dC, iters, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
